---
title: "Empirical Q"
output: html_notebook
---

```{r}
library(dplyr)
library(lubridate)
source('ACCode.R')
```

### Just Replicate Figure 1

```{r}
# prep stock data
nvidia_raw <- read.csv('data/Nvidia.csv')
fm_raw <- read.csv('data/FannieMae.csv')
# we want to start 1250 days before 1/1/2005: 6/31/2001
nvidia_raw$t <- as.Date(nvidia_raw$Date, "%m/%d/%y")
nvidia_raw <- nvidia_raw %>% arrange(t) 
nvidia <- nvidia_raw %>% filter(t>"2001-06-30")
fm_raw$t <- as.Date(fm_raw$Date, "%m/%d/%y")
fm_raw <- fm_raw %>% arrange(t) 
fm <- fm_raw %>% filter(t>"2001-06-30")

# prep series
nvidia_returns <- diff(nvidia$Open,differences=1,lag=1)/nvidia$Open[1:(nrow(nvidia)-1)]
nvidia_volatility <- nvidia_returns**2
fm_returns <- diff(fm$Open,differences=1,lag=1)/fm$Open[1:(nrow(fm)-1)]
fm_volatility <- fm_returns**2
```

```{r}
plot(nvidia$t[1:(nrow(nvidia)-1)],nvidia_returns,'l',main='NVIDIA Returns')
plot(nvidia$t[1:(nrow(nvidia)-1)],nvidia_volatility,'l',main='NVIDIA Volatility')
plot(fm$t[1:(nrow(fm)-1)],fm_returns,'l',main='Fannie Mae Returns')
plot(fm$t[1:(nrow(fm)-1)],fm_volatility,'l',main='Fannie Mae Volatility')
```


```{r}
# confirm we can replicate. note: this is quite slow
nvidia_out <- garchConformalForcasting(nvidia_returns,alpha=0.1,gamma=0.005)
fm_out <- garchConformalForcasting(fm_returns,alpha=0.1,gamma=0.005)
```


```{r}
local_coverage_rate <- function(error){
  local_coverage <- rep(0,length(error))
  error <- c(rep(NaN,250),error,rep(NaN,250))  # pad with NaN
  for (t in 250:(length(error)-250)){
    local_coverage[t-250] <- 1 - (sum(error[(t-250+1):(t+250)])/sum(!is.na(error[(t-250+1):(t+250)])))}
  return(local_coverage)
}

plot(nvidia$t[1250:(length(nvidia_out[2][[1]])+1250-1)],local_coverage_rate(nvidia_out[2][[1]]),'l',col='blue',xlab='Time',ylab='Local Coverage Level',main='NVIDIA')
lines(nvidia$t[1250:(length(nvidia_out[3][[1]])+1250-1)],local_coverage_rate(nvidia_out[3][[1]]),'l',col='red')
lines(nvidia$t[1250:(length(nvidia_out[3][[1]])+1250-1)],local_coverage_rate(rbinom(n=length(nvidia_out[3][[1]]),size=1,p=0.1)),'l',col='grey')
abline(h=0.9)

plot(fm$t[1250:(length(fm_out[2][[1]])+1250-1)],local_coverage_rate(fm_out[2][[1]]),'l',col='blue',xlab='Time',ylab='Local Coverage Level',main='Fannie Mae')
lines(fm$t[1250:(length(fm_out[3][[1]])+1250-1)],local_coverage_rate(fm_out[3][[1]]),'l',col='red')
lines(nvidia$t[1250:(length(nvidia_out[3][[1]])+1250-1)],local_coverage_rate(rbinom(n=length(nvidia_out[3][[1]]),size=1,p=0.1)),'l',col='grey')
abline(h=0.9)
```

```{r}
# look at how much alpha_t changes, which they didn't show
plot(nvidia$t[1250:(length(nvidia_out[1][[1]])+1250-1)],local_coverage_rate(nvidia_out[1][[1]]),'l',col='blue',xlab='Time',ylab='Local Coverage Level',main='NVIDIA Alpha_t')
abline(h=.9)
plot(fm$t[1250:(length(fm_out[1][[1]])+1250-1)],local_coverage_rate(fm_out[1][[1]]),'l',col='blue',xlab='Time',ylab='Local Coverage Level',main='Fannie Mae Alpha_t')
abline(h=.9)
```

### How Much Does Q Change?

```{r}

# modify the function to fix Q and S in time

garchConformalForcasting_fixedQS <- function(returns,alpha,gamma,lookback=1250,garchP=1,garchQ=1,startUp = 100,verbose=FALSE,updateMethod="Simple",momentumBW = 0.95){
  T <- length(returns)
  startUp <- max(startUp,lookback)
  garchSpec <- ugarchspec(mean.model=list(armaOrder = c(0, 0),include.mean=FALSE),variance.model=list(model="sGARCH",garchOrder=c(1,1)),distribution.model="norm")
  alphat <- alpha
  ### Initialize data storage variables
  errSeqOC <- rep(0,T-startUp+1)
  errSeqNC <- rep(0,T-startUp+1)
  alphaSequence <- rep(alpha,T-startUp+1)
  scores <- rep(0,T-startUp+1+1250)
  
  # start up!
  garchFit <- ugarchfit(garchSpec, returns[(startUp-lookback+1):(startUp-1) ],solver="hybrid")
  sigmaNext <- sigma(ugarchforecast(garchFit,n.ahead=1250))  # 1250 calibration set
  scores[1:1250] <- abs(returns[startUp]^2- sigmaNext^2)/sigmaNext^2  # use these scores forever!
  
  for(t in startUp+1:T){
    if(verbose){
      print(t)
    }
    sigmaNext <- sigma(ugarchforecast(garchFit,n.ahead=1250+t))
    sigmaNext <- sigmaNext[length(sigmaNext)]
    scores[1250 + t-startUp] <- abs(returns[t]^2- sigmaNext^2)/sigmaNext^2
    
    ### compute errt for both methods
    errSeqOC[t-startUp+1] <- as.numeric(scores[t-startUp + 1] > quantile(scores[1],1-alphat))
    errSeqNC[t-startUp+1] <- as.numeric(scores[t-startUp + 1] > quantile(scores[1],1-alpha))
    
    ### update alphat
    alphaSequence[t-startUp+1] <- alphat
    if(updateMethod=="Simple"){
      alphat <- alphat + gamma*(alpha - errSeqOC[t-startUp+1])
    }else if(updateMethod=="Momentum"){
      w <- rev(momentumBW^(1:(t-startUp+1)))
      w <- w/sum(w)
      alphat <- alphat + gamma*(alpha - sum(errSeqOC[1:(t-startUp+1)]*w))
    }
    # ensure alphat is between 0 and 1
    alphat <- max(alphat,0)
    alphat <- min(alphat,1)
    if(t %% 100 == 0){
      print(sprintf("Done %g steps",t))
    }
  }
  
  return(list(alphaSequence,errSeqOC,errSeqNC))
}
```

```{r}
nvidia_out_fixed <- garchConformalForcasting_fixedQS(nvidia_returns,alpha=0.1,gamma=0.005)
fm_out_fixed <- garchConformalForcasting_fixedQS(fm_returns,alpha=0.1,gamma=0.005)
```

```{r}

plot(nvidia$t[1250:(length(nvidia_out_fixed[2][[1]])+1250-1)],local_coverage_rate(nvidia_out_fixed[2][[1]]),'l',col='blue',xlab='Time',ylab='Local Coverage Level',main='NVIDIA')
lines(nvidia$t[1250:(length(nvidia_out_fixed[3][[1]])+1250-1)],local_coverage_rate(nvidia_out_fixed[3][[1]]),'l',col='red')
lines(nvidia$t[1250:(length(nvidia_out_fixed[3][[1]])+1250-1)],local_coverage_rate(rbinom(n=length(nvidia_out_fixed[3][[1]]),size=1,p=0.1)),'l',col='grey')
abline(h=0.9)

plot(fm$t[1250:(length(fm_out_fixed[2][[1]])+1250-1)],local_coverage_rate(fm_out_fixed[2][[1]]),'l',col='blue',xlab='Time',ylab='Local Coverage Level',main='Fannie Mae')
lines(fm$t[1250:(length(fm_out_fixed[3][[1]])+1250-1)],local_coverage_rate(fm_out_fixed[3][[1]]),'l',col='red')
lines(fm$t[1250:(length(fm_out_fixed[3][[1]])+1250-1)],local_coverage_rate(rbinom(n=length(fm_out_fixed[3][[1]]),size=1,p=0.1)),'l',col='grey')
abline(h=0.9)
```



